version: '3.7'
services:

  spacyapi:
    image: jgontrum/spacyapi:all_v2
    hostname: spacyapi
    domainname: pontus-demo.com
    restart: on-failure
    container_name: spacyapi.pontus-demo.com
    networks:
      pontusvision:
        ipv4_address: 172.28.1.1



#  elasticsearch:
#    image: "elasticsearch:6.7.2"
#    domainname: pontus-demo.com
#    ports:
#      - "9200:9200"
#      - "9300:9300"
#    restart: on-failure
#    privileged: false
#    hostname: elasticsearch
#    container_name: elasticsearch.pontus-demo.com
#    environment:
#      - node.name=elasticsearch
#      - discovery.type=single-node
#      - cluster.name=docker-cluster
#      - "ES_JAVA_OPTS=-Xms2048m -Xmx2048m"
#    networks:
#      pontusvision:
#        ipv4_address: 172.28.1.2
#    ulimits:
#      memlock:
#        soft: -1
#        hard: -1
#

  graphdb-nifi:
    image: "pontusvisiongdpr/pontus-track-graphdb-odb:latest"
    domainname: pontus-demo.com
    ports:
      - "8182:8183"
      - "8183:8183"
      - "7000:7000"
      - "3001:3001"
      - "5009:5007"
    restart: on-failure
    privileged: false
    hostname: graphdb-nifi
    container_name: graphdb-nifi.pontus-demo.com
    secrets:
      - MAPPING_SALESFORCE_GRAPH
    #depends_on:
      #- elasticsearch
    networks:
      pontusvision:
        ipv4_address: 172.28.1.3
    command: >
      /bin/bash -c "
        #echo Waiting for elasticsearch service start...;
        #while ! nc -z elasticsearch 9200;
        #do
          #sleep 1;
        #done;
        echo Connected!;
        LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/tmp /orientdb/bin/server.sh 
      "



  pontus-nifi:
    image: "pontusvisiongdpr/pontus-extract-nifi:latest"
    domainname: pontus-demo.com
    ports:
      - "8080:8080"
      - "5006:5006"
      - "5007:5007"
    restart: on-failure
    privileged: false
    hostname: pontus-nifi
    container_name: pontus-nifi.pontus-demo.com
    secrets:
      - SALESFORCE_CLIENT_ID
      - SALESFORCE_CLIENT_SECRET
      - SALESFORCE_USERNAME
      - SALESFORCE_PASSWORD
      - OFFICE_365_AUTH_CLIENT_SECRET
      - OFFICE_365_AUTH_CLIENT_ID
      - OFFICE_365_AUTH_TENANT_ID
      - WATSON_USER_NAME
      - WATSON_PASSWORD
      - GOOGLE_CREDS_JSON

    volumes:
      - "./nifi-nlp:/var/run/nifi-nlp"


    depends_on:
      - pontus-postgrest
      - graphdb-nifi
      - mysql
      - spacyapi
    networks:
      pontusvision:
        ipv4_address: 172.28.1.4
    entrypoint: >
      /bin/bash -c "
        getent hosts spacyapi
        echo Waiting for graphdb-nifi service start...;
        while [[ `/usr/bin/curl -s  -H 'Content-Type: application/json' -X POST -d '' http://graphdb-nifi:3001/home/vertex_labels` != *Object.Data_Source* ]] ; do
          sleep 1;
          echo waiting for graph to be ready ... got $$(/usr/bin/curl -s  -H 'Content-Type: application/json' -X POST -d '' http://graphdb-nifi:3001/home/vertex_labels);
        done;
        export RES=$$(/usr/bin/curl -s  -H 'Content-Type: application/json' -X POST -d '' http://graphdb-nifi:3001/home/vertex_labels);
        echo Waiting for vertex_labels... got this: $$RES;
        echo Connected!;
        ../scripts/start.sh
      "


  pontus-formio-mongodb:
    image: "pontusvisiongdpr/pontus-formio-mongodb:latest"
    domainname: pontus-demo.com
    ports:
      - "27017:27017"
    restart: on-failure
    privileged: false
    hostname: pontus-formio-mongodb
    container_name: pontus-formio-mongodb.pontus-demo.com
    command: >
      /bin/bash -c "
        docker-entrypoint.sh mongod &
        if [[ ! -f /data/db/pv-init ]]; then
          sleep 5 
          mongorestore /mongodb  
          sleep 5 
          touch /data/db/pv-init
        fi
        wait %1
      "
    networks:
      pontusvision:
        ipv4_address: 172.28.1.5



  pontus-formio:
    image: "pontusvisiongdpr/pontus-formio:latest"
    domainname: pontus-demo.com
    ports:
      - "3005:3005"
      - "8085:8085"
    restart: on-failure
    privileged: true
    hostname: pontus-formio
    container_name: pontus-formio.pontus-demo.com
    depends_on:
      - pontus-formio-mongodb
    command: >
      /bin/bash -c "
        echo Waiting for mongodb service start...;
        while ! nc -z pontus-formio-mongodb 27017;
        do
          sleep 1;
        done;
        sleep 10;
        echo Connected!;
        /opt/pontus/pontus-formio/current/bin/run-gui.sh
        #while [[ true ]]; do sleep 1; done
      "
    networks:
      pontusvision:
        ipv4_address: 172.28.1.6



  pontus-comply-keycloak:
    image: "pontusvisiongdpr/pontus-comply-keycloak:latest"
    domainname: pontus-demo.com
    hostname: pontus-comply-keycloak
    container_name: pontus-comply-keycloak.pontus-demo.com
    ports:
      - "5005:8080"
    restart: on-failure
    privileged: true
    networks:
      pontusvision:
        ipv4_address: 172.28.1.7



#  pontus-extract-discovery-backend:
#    image: "pontusvisiongdpr/pontus-extract-discovery-backend"
#    domainname: pontus-demo.com
#    hostname: pontus-extract-discovery-backend
#    container_name: pontus-extract-discovery-backend.pontus-demo.com
#    ports:
#      - "8888:8888"
#      - "5008:5008"
#    restart: on-failure
#    privileged: true
#    networks:
#      - pontusvision
#
#    depends_on:
#      - pontus-extract-discovery-dataset
#      - pontus-extract-discovery-transformation
#      - pontus-extract-discovery-preparation
#
#    command: >
#      /bin/bash -c "
#         mkdir -p /tmp/AppData/Roaming/Talend/dataprep/store/datasets/metadata 
#         mkdir -p /tmp/AppData/Roaming/Talend/dataprep/store/preparations
#         mkdir -p /tmp/AppData/Roaming/Talend/dataprep/store/users
#         mkdir -p /tmp/AppData/Roaming/Talend/dataprep/store/folders
#         mkdir -p /tmp/AppData/Roaming/Talend/dataprep/store/upgrade
#         getent hosts pontus-extract-discovery-dataset
#         getent hosts pontus-extract-discovery-transformation
#         getent hosts pontus-extract-discovery-preparation
#         echo Waiting for pontus-nifi service start just to reduce the number of JVMs starting at once...;
#         while ! nc -z pontus-nifi 8080;
#         do
#           sleep 1;
#         done;
#         java  -Dserver.port=8888  -Dspring.profiles.active=standalone -Dspring.mvc.favicon.enabled=false -Dserver.compression.enabled=true -Dserver.compression.mime-types=text/plain,application/json -Dspring.mvc.async.request-timeout=300000 -Dservice.documentation=false -Dservice.documentation.name='Talend Data Preparation - API' -Dservice.documentation.description='This service exposes high level services that may involve services orchestration.' -Dservice.paths=api -Ddataset.records.limit=30000 -Ddataset.local.file.size.limit=2000000000 -Ddataset.list.limit=10 -Ddataset.imports=local -Ddataset.service.url=http://pontus-extract-discovery-dataset:8288/ -Dtransformation.service.url=http://pontus-extract-discovery-transformation:8388/ -Dpreparation.service.url=http://pontus-extract-discovery-preparation:8188/ -Ddataset.metadata.store=file -Dpreparation.store=file -Duser.data.store=file -Dfolder.store=file -Dupgrade.store=file -Ddataset.metadata.store.file.location=/tmp/AppData/Roaming/Talend/dataprep/store/datasets/metadata/ -Dpreparation.store.file.location=/tmp/AppData/Roaming/Talend/dataprep/store/preparations/ -Duser.data.store.file.location=/tmp/AppData/Roaming/Talend/dataprep/store/users/ -Dfolder.store.file.location=/tmp/AppData/Roaming/Talend/dataprep/store/folders/ -Dupgrade.store.file.location=/tmp/AppData/Roaming/Talend/dataprep/store/upgrade -Dcontent-service.store=local -Dcontent-service.store.local.path=/tmp/AppData/Roaming/Talend/dataprep/ -Dpreparation.store.remove.hours=24 -DluceneIndexStrategy=singleton -Ddataquality.indexes.file.location=/tmp/AppData/Roaming/Talend/dataprep/data-quality/2.5.1/org.talend.dataquality.semantic -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5008 -jar /opt/pontus-extract/discovery/lib/dataprep-api.jar
#      "
#  
#
#  pontus-extract-discovery-transformation:
#    image: "pontusvisiongdpr/pontus-extract-discovery-backend"
#    domainname: pontus-demo.com
#    hostname: pontus-extract-discovery-transformation
#    container_name: pontus-extract-discovery-transformation.pontus-demo.com
#    restart: on-failure
#    privileged: true
#    networks:
#      - pontusvision
#
#    command: >
#      /bin/bash -c "
#         mkdir -p /tmp/AppData/Roaming/Talend/dataprep/store/datasets/metadata 
#         mkdir -p /tmp/AppData/Roaming/Talend/dataprep/store/preparations
#         mkdir -p /tmp/AppData/Roaming/Talend/dataprep/store/users
#         mkdir -p /tmp/AppData/Roaming/Talend/dataprep/store/folders
#         mkdir -p /tmp/AppData/Roaming/Talend/dataprep/store/upgrade
#         echo Waiting for pontus-nifi service start just to reduce the number of JVMs starting at once...;
#         while ! nc -z pontus-nifi 8080;
#         do
#           sleep 1;
#         done;
#         java  -Dserver.port=8388  -Dspring.profiles.active=standalone -Dspring.mvc.favicon.enabled=false -Dserver.compression.enabled=true -Dserver.compression.mime-types=text/plain,application/json -Dspring.mvc.async.request-timeout=300000 -Dservice.documentation=false -Dservice.documentation.name='Talend Data Preparation - API' -Dservice.documentation.description='This service exposes high level services that may involve services orchestration.' -Dservice.paths=api -Ddataset.records.limit=30000 -Ddataset.local.file.size.limit=2000000000 -Ddataset.list.limit=10 -Ddataset.imports=local -Ddataset.service.url=http://pontus-extract-discovery-dataset:8288/ -Dtransformation.service.url=http://pontus-extract-discovery-transformation:8388/ -Dpreparation.service.url=http://pontus-extract-discovery-preparation:8188/ -Ddataset.metadata.store=file -Dpreparation.store=file -Duser.data.store=file -Dfolder.store=file -Dupgrade.store=file -Ddataset.metadata.store.file.location=/tmp/AppData/Roaming/Talend/dataprep/store/datasets/metadata/ -Dpreparation.store.file.location=/tmp/AppData/Roaming/Talend/dataprep/store/preparations/ -Duser.data.store.file.location=/tmp/AppData/Roaming/Talend/dataprep/store/users/ -Dfolder.store.file.location=/tmp/AppData/Roaming/Talend/dataprep/store/folders/ -Dupgrade.store.file.location=/tmp/AppData/Roaming/Talend/dataprep/store/upgrade -Dcontent-service.store=local -Dcontent-service.store.local.path=/tmp/AppData/Roaming/Talend/dataprep/ -Dpreparation.store.remove.hours=24 -DluceneIndexStrategy=singleton -Ddataquality.indexes.file.location=/tmp/AppData/Roaming/Talend/dataprep/data-quality/2.5.1/org.talend.dataquality.semantic -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5008 -jar /opt/pontus-extract/discovery/lib/dataprep-transformation.jar
#      "
#  
#
#  pontus-extract-discovery-dataset:
#    image: "pontusvisiongdpr/pontus-extract-discovery-backend"
#    domainname: pontus-demo.com
#    hostname: pontus-extract-discovery-dataset
#    container_name: pontus-extract-discovery-dataset.pontus-demo.com
#    restart: on-failure
#    privileged: true
#    ports: 
#      - "8288:8288"
#    networks:
#      - pontusvision
#
#    command: >
#      /bin/bash -c "
#         mkdir -p /tmp/AppData/Roaming/Talend/dataprep/store/datasets/metadata 
#         mkdir -p /tmp/AppData/Roaming/Talend/dataprep/store/preparations
#         mkdir -p /tmp/AppData/Roaming/Talend/dataprep/store/users
#         mkdir -p /tmp/AppData/Roaming/Talend/dataprep/store/folders
#         mkdir -p /tmp/AppData/Roaming/Talend/dataprep/store/upgrade
#         echo Waiting for pontus-nifi service start just to reduce the number of JVMs starting at once...;
#         while ! nc -z pontus-nifi 8080;
#         do
#           sleep 1;
#         done;
#         java  -Dserver.port=8288  -Dspring.profiles.active=standalone -Dspring.mvc.favicon.enabled=false -Dserver.compression.enabled=true -Dserver.compression.mime-types=text/plain,application/json -Dspring.mvc.async.request-timeout=300000 -Dservice.documentation=false -Dservice.documentation.name='Talend Data Preparation - API' -Dservice.documentation.description='This service exposes high level services that may involve services orchestration.' -Dservice.paths=api -Ddataset.records.limit=30000 -Ddataset.local.file.size.limit=2000000000 -Ddataset.list.limit=10 -Ddataset.imports=local -Ddataset.service.url=http://pontus-extract-discovery-dataset:8288/ -Dtransformation.service.url=http://pontus-extract-discovery-transformation:8388/ -Dpreparation.service.url=http://pontus-extract-discovery-preparation:8188/ -Ddataset.metadata.store=file -Dpreparation.store=file -Duser.data.store=file -Dfolder.store=file -Dupgrade.store=file -Ddataset.metadata.store.file.location=/tmp/AppData/Roaming/Talend/dataprep/store/datasets/metadata/ -Dpreparation.store.file.location=/tmp/AppData/Roaming/Talend/dataprep/store/preparations/ -Duser.data.store.file.location=/tmp/AppData/Roaming/Talend/dataprep/store/users/ -Dfolder.store.file.location=/tmp/AppData/Roaming/Talend/dataprep/store/folders/ -Dupgrade.store.file.location=/tmp/AppData/Roaming/Talend/dataprep/store/upgrade -Dcontent-service.store=local -Dcontent-service.store.local.path=/tmp/AppData/Roaming/Talend/dataprep/ -Dpreparation.store.remove.hours=24 -DluceneIndexStrategy=singleton -Ddataquality.indexes.file.location=/tmp/AppData/Roaming/Talend/dataprep/data-quality/2.5.1/org.talend.dataquality.semantic -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5008 -jar /opt/pontus-extract/discovery/lib/dataprep-dataset.jar
#      "
#  
#
#  pontus-extract-discovery-preparation:
#    image: "pontusvisiongdpr/pontus-extract-discovery-backend"
#    domainname: pontus-demo.com
#    hostname: pontus-extract-discovery-preparation
#    container_name: pontus-extract-discovery-preparation.pontus-demo.com
#    restart: on-failure
#    privileged: true
#    networks:
#      - pontusvision
#
#    command: >
#      /bin/bash -c "
#         mkdir -p /tmp/AppData/Roaming/Talend/dataprep/store/datasets/metadata 
#         mkdir -p /tmp/AppData/Roaming/Talend/dataprep/store/preparations
#         mkdir -p /tmp/AppData/Roaming/Talend/dataprep/store/users
#         mkdir -p /tmp/AppData/Roaming/Talend/dataprep/store/folders
#         mkdir -p /tmp/AppData/Roaming/Talend/dataprep/store/upgrade
#         echo Waiting for pontus-nifi service start just to reduce the number of JVMs starting at once...;
#         while ! nc -z pontus-nifi 8080;
#         do
#           sleep 1;
#         done;
#         java  -Dserver.port=8188  -Dspring.profiles.active=standalone -Dspring.mvc.favicon.enabled=false -Dserver.compression.enabled=true -Dserver.compression.mime-types=text/plain,application/json -Dspring.mvc.async.request-timeout=300000 -Dservice.documentation=false -Dservice.documentation.name='Talend Data Preparation - API' -Dservice.documentation.description='This service exposes high level services that may involve services orchestration.' -Dservice.paths=api -Ddataset.records.limit=30000 -Ddataset.local.file.size.limit=2000000000 -Ddataset.list.limit=10 -Ddataset.imports=local -Ddataset.service.url=http://pontus-extract-discovery-dataset:8288/ -Dtransformation.service.url=http://pontus-extract-discovery-transformation:8388/ -Dpreparation.service.url=http://pontus-extract-discovery-preparation:8188/ -Ddataset.metadata.store=file -Dpreparation.store=file -Duser.data.store=file -Dfolder.store=file -Dupgrade.store=file -Ddataset.metadata.store.file.location=/tmp/AppData/Roaming/Talend/dataprep/store/datasets/metadata/ -Dpreparation.store.file.location=/tmp/AppData/Roaming/Talend/dataprep/store/preparations/ -Duser.data.store.file.location=/tmp/AppData/Roaming/Talend/dataprep/store/users/ -Dfolder.store.file.location=/tmp/AppData/Roaming/Talend/dataprep/store/folders/ -Dupgrade.store.file.location=/tmp/AppData/Roaming/Talend/dataprep/store/upgrade -Dcontent-service.store=local -Dcontent-service.store.local.path=/tmp/AppData/Roaming/Talend/dataprep/ -Dpreparation.store.remove.hours=24 -DluceneIndexStrategy=singleton -Ddataquality.indexes.file.location=/tmp/AppData/Roaming/Talend/dataprep/data-quality/2.5.1/org.talend.dataquality.semantic -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5008 -jar /opt/pontus-extract/discovery/lib/dataprep-preparation.jar
#      " 


  pontus-lgpd:
    image: "pontusvisiongdpr/pontus-comply-nginx-lgpd:latest"
    domainname: pontus-demo.com
    ports:
      - "18443:18443"
    restart: on-failure
    privileged: true
    hostname: pontus-lgpd
    container_name: pontus-lgpd.pontus-demo.com
    networks:
      pontusvision:
        ipv4_address: 172.28.1.11
    depends_on:
      - pontus-formio-mongodb
      - pontus-formio
      - pontus-nifi
      - pontus-comply-keycloak
      # - pontus-extract-discovery-backend

    command: >
      /bin/bash -c "
         getent hosts pontus-formio.pontus-demo.com
         getent hosts pontus-nifi.pontus-demo.com
         getent hosts pontus-comply-keycloak.pontus-demo.com
         echo Waiting for pontus-nifi service start just to reduce the number of JVMs starting at once...;
         nginx-debug -g 'daemon off;'
      "

  pontus-timescaledb:
    image: "pontusvisiongdpr/timescaledb:latest"
    domainname: pontus-demo.com
    restart: on-failure
    hostname: pontus-timescaledb
    container_name: pontus-timescaledb.pontus-demo.com
    networks:
      pontusvision:
        ipv4_address: 172.28.1.12
    env_file:
      - secrets/PONTUS-TIMESCALEDB


  pontus-grafana:
    image: "pontusvisiongdpr/grafana:latest"
    domainname: pontus-demo.com
    restart: on-failure
    hostname: pontus-grafana
    container_name: pontus-grafana.pontus-demo.com
    depends_on:
      - pontus-timescaledb
      - pontus-lgpd

    networks:
      pontusvision:
        ipv4_address: 172.28.1.13
    env_file:
      - secrets/PONTUS-GRAFANA
    entrypoint: >
      bash -c "
        getent hosts pontus-lgpd &&
        # we need to do this hack to redirect localhost:18443 to the pontus-lgpd gateway to get
        # the JWT token.
        while nc -l -p 18443 -k -c 'nc pontus-lgpd 18443' || true; do true; done &
        /run.sh

      "


  pontus-postgrest:
    image: "pontusvisiongdpr/postgrest:latest"
    domainname: pontus-demo.com
    restart: on-failure
    hostname: pontus-postgrest
    container_name: pontus-postgrest.pontus-demo.com
    depends_on:
      - pontus-timescaledb

    networks:
      pontusvision:
        ipv4_address: 172.28.1.14
    env_file:
      - secrets/PONTUS-POSTGREST

  mysql:
    build: ./mysql
    hostname: mysql
    domainname: pontus-demo.com
    container_name: mysql.pontus-demo.com
  #  command: --default-authentication-plugin=mysql_native_password
    restart: always
    privileged: true
    environment:
#      MYSQL_DATABASE: jwdb 
      MYSQL_DATABASE: employees 
      MYSQL_PORT: 3306 
      MYSQL_USER: joget
      MYSQL_PASSWORD: joget
      MYSQL_ROOT_PASSWORD: jwdb
    healthcheck:
      test: mysqladmin ping -h 127.0.0.1 -u $$MYSQL_USER --password=$$MYSQL_PASSWORD
      interval: 30s
      timeout: 10s
      retries: 5


    networks:
      pontusvision:
        ipv4_address: 172.28.1.15

#  joget:
#    image: jogetworkflow/joget-community
#    hostname: joget
#    domainname: pontus-demo.com
#    container_name: joget.pontus-demo.com
#    depends_on:
#      - mysql
#
#    restart: always
#    ports:
#      - "4000:8080"
#    environment:
#      MYSQL_ROOT_PASSWORD: jwdb
#      MYSQL_HOST: mysql.pontus-demo.com 
#      MYSQL_DATABASE: jwdb 
#      MYSQL_PORT: 3306 
#      MYSQL_USER: joget
#      MYSQL_PASSWORD: joget
#
#    networks:
#      - pontusvision
    




networks:
  pontusvision:
    ipam:
      driver: default
      config:
        - subnet: 172.28.0.0/16


secrets:
  SALESFORCE_CLIENT_ID:
    file: secrets/SALESFORCE_CLIENT_ID
  SALESFORCE_CLIENT_SECRET:
    file:  secrets/SALESFORCE_CLIENT_SECRET
  SALESFORCE_USERNAME:
    file: secrets/SALESFORCE_USERNAME
  SALESFORCE_PASSWORD:
    file: secrets/SALESFORCE_PASSWORD
  OFFICE_365_AUTH_CLIENT_SECRET:
    file: secrets/OFFICE_365_AUTH_CLIENT_SECRET
  OFFICE_365_AUTH_CLIENT_ID:
    file: secrets/OFFICE_365_AUTH_CLIENT_ID
  OFFICE_365_AUTH_TENANT_ID:
    file: secrets/OFFICE_365_AUTH_TENANT_ID
  WATSON_USER_NAME:
    file: secrets/WATSON_USER_NAME
  WATSON_PASSWORD:
    file: secrets/WATSON_PASSWORD
  GOOGLE_CREDS_JSON:
    file: secrets/GOOGLE_CREDS_JSON
  MAPPING_SALESFORCE_GRAPH:
    file: secrets/MAPPING_SALESFORCE_GRAPH

